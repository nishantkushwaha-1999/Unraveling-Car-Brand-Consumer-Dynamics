{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1129352-3130-44bd-957e-dbbdd20a9c01",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Team Members Name (eid):\n",
    "1. Ko Choi (kec788)\n",
    "2. Mandeep Burdak (msb4384)\n",
    "3. Nishant Kushwaha (nsk779)\n",
    "4. Pratyush Sharma (ps35484)\n",
    "5. Vaibhav Nagar (vn5339)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39ffea93-61ae-4f87-bb0e-07274a9e7462",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 1. Scraper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9fad990-3a1c-464a-9c6a-6c8de13caa61",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import statsmodels.api as sm\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "from sklearn.manifold import MDS\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef9cb50c-7837-4aea-a4b2-52234fef6ce4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "path = '/mnt/car_brand_attribute_associations/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e800f5f7-dc18-4141-ad69-060bece09fa6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "wd = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "n = 6000\n",
    "data = {}\n",
    "user_dict = {}\n",
    "posts_dict = {}\n",
    "time_dict = {}\n",
    "i = 435\n",
    "while len(data) < n:\n",
    "    url = 'https://forums.edmunds.com/discussion/2864/general/x/entry-level-luxury-performance-sedans' + \"/p\" + str(i)\n",
    "    wd.get(url)\n",
    "\n",
    "    comments = wd.find_elements(By.CLASS_NAME, value=\"Comment\")\n",
    "\n",
    "    for comment in reversed(comments): \n",
    "        user = comment.find_element(By.TAG_NAME, \"a\").get_attribute('href')\n",
    "        user = user.split('/')[-1]\n",
    "        \n",
    "        posts = comment.find_element(by=By.CLASS_NAME, value=\"AuthorInfo\")\n",
    "        posts = posts.find_element(by=By.TAG_NAME, value=\"b\").text\n",
    "        posts = posts.split(',')\n",
    "        posts = \"\".join(posts)\n",
    "        \n",
    "        time = comment.find_element(by=By.TAG_NAME, value=\"time\").get_attribute(\"datetime\")\n",
    "\n",
    "        try:\n",
    "            backquote = comment.find_element(by=By.CLASS_NAME, value=\"Item-BodyWrap\")\n",
    "            backquote = backquote.find_element(by=By.TAG_NAME, value=\"blockquote\")\n",
    "            backquote = backquote.find_element(by=By.CLASS_NAME, value=\"QuoteText.blockquote-content\").text\n",
    "            backquote = backquote.split()\n",
    "            backquote = \" \".join(backquote)\n",
    "            backquote = backquote.strip()\n",
    "        except:\n",
    "            backquote = \"\"\n",
    "        \n",
    "        comment_text = comment.find_element(by=By.CLASS_NAME, value=\"Item-BodyWrap\")\n",
    "        comment_text = comment.find_element(by=By.CLASS_NAME, value=\"Message.userContent\").text\n",
    "        comment_text = comment_text.split()\n",
    "        comment_text = \" \".join(comment_text)\n",
    "        comment_text = comment_text.strip()\n",
    "\n",
    "        try:\n",
    "            sub_text = comment.find_element(by=By.CLASS_NAME, value=\"Item-BodyWrap\")\n",
    "            sub_text = sub_text.find_element(by=By.TAG_NAME, value=\"blockquote\").text\n",
    "            sub_text = sub_text.split()\n",
    "            sub_text = \" \".join(sub_text)\n",
    "            sub_text = sub_text.strip()\n",
    "        except:\n",
    "            sub_text = ''\n",
    "\n",
    "        comment_text = comment_text.replace(sub_text, \"\").strip()\n",
    "\n",
    "        user_dict[comment_text] = user\n",
    "        posts_dict[comment_text] = posts\n",
    "        time_dict[comment_text] = time\n",
    "\n",
    "        if backquote != \"\":\n",
    "            if comment_text in data.keys():\n",
    "                text = [comment_text]\n",
    "                for j in data[comment_text]:\n",
    "                    text.append(j)\n",
    "                data[backquote] = text\n",
    "                del data[comment_text]\n",
    "            else:\n",
    "                data[backquote] = [comment_text]\n",
    "        else:\n",
    "            if comment_text not in data.keys():\n",
    "                data[comment_text] = []\n",
    "\n",
    "    l = 30\n",
    "    d = int((len(data)/n) * l)\n",
    "    sys.stdout.write(\"\\rCollecing samples from {1}: {0}>\".format(\"=\"*d + \".\"*(l-d-1), url))\n",
    "    sys.stdout.flush()\n",
    "    i = int(i)\n",
    "    i = i - 1\n",
    "wd.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7587838f-9a60-4d1e-992c-35a968109686",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "edmunds = []\n",
    "for key in data.keys():\n",
    "    text = ' '\n",
    "    text += key\n",
    "    for j in data[key]:\n",
    "        text += ' ' + j\n",
    "    text.strip()\n",
    "\n",
    "    try:\n",
    "        user = user_dict[key]\n",
    "    except KeyError:\n",
    "        user = None\n",
    "    \n",
    "    try: \n",
    "        n_posts = posts_dict[key]\n",
    "    except KeyError:\n",
    "        n_posts = None\n",
    "\n",
    "    try:\n",
    "        time = time_dict[key]\n",
    "    except KeyError:\n",
    "        time = None\n",
    "    \n",
    "    edmunds.append([user, time, text, n_posts])\n",
    "\n",
    "edmunds = pd.DataFrame(edmunds, columns=['User', 'Post Time', 'Comment', '#Posts by User'])\n",
    "edmunds['Post Time'] = pd.to_datetime(edmunds['Post Time'])\n",
    "edmunds = edmunds.loc[~edmunds['Comment'].isnull()]\n",
    "edmunds = edmunds.loc[~edmunds['Post Time'].isnull()]\n",
    "edmunds = edmunds[:5000]\n",
    "df_spark = spark.createDataFrame(edmunds)\n",
    "df_spark.write.option(\"header\", \"true\").mode(\"overwrite\").csv(path+'Data/Edmunds_Data_New')\n",
    "edmunds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52bfa69a-9588-484a-8f8b-f81924e85005",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### OLS- Zipf's Law verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21a50b91-3513-4fd8-afc3-cd252f14e4ed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "edmunds_data = edmunds\n",
    "edmunds_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fdf2a8bf-db3f-45f9-aa99-952580a17bc7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generate_corpus(column):\n",
    "    corpus = \" \"\n",
    "    for text in column:\n",
    "        text = str(text)\n",
    "        for i in list(string.punctuation.replace('+','')):\n",
    "            text = text.replace(i, ' ')\n",
    "        text = text.lower()\n",
    "\n",
    "        corpus += text\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24655935-da2b-4dc6-a72b-586a3e7ca1b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "corpus = generate_corpus(edmunds_data['Comment'])\n",
    "corpus = corpus.split()\n",
    "print(len(corpus))\n",
    "\n",
    "word_freq = FreqDist()\n",
    "for word in tqdm(corpus):\n",
    "    word_freq[word] += 1\n",
    "\n",
    "freq_dist = []\n",
    "for rank, word in enumerate(word_freq):\n",
    "    freq_dist.append([rank+1, word, word_freq[word]])\n",
    "\n",
    "freq_dist = pd.DataFrame(freq_dist, columns=['Rank', 'Word', 'Count'])\n",
    "df = spark.createDataFrame(freq_dist)\n",
    "df.write.option(\"header\", \"true\").mode(\"overwrite\").csv(path+ 'Support Files/Freq_Dist_new_comments')\n",
    "freq_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "360691eb-8e09-463c-ba30-6e2810d6279f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "max_rank = max(freq_dist['Rank'])\n",
    "c = max_rank * int(freq_dist.loc[freq_dist['Rank'] == max_rank]['Count'].values)\n",
    "\n",
    "l_rank = np.log(freq_dist['Rank'] / c)\n",
    "l_freq = np.log(freq_dist['Count'])\n",
    "\n",
    "# X = sm.add_constant(l_rank)\n",
    "model = sm.OLS(l_freq, l_rank)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c135a126-8fc3-49d0-ae1f-a4e709147cf7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,7))\n",
    "plt.plot(l_freq, l_rank, label=\"Raw Zipf's Curve\")\n",
    "plt.plot(result.predict(l_rank), l_rank, label='OLS Fit')\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(\"Zipf's Distribution\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df5e8ad5-b13b-4367-9eb8-5617122bb360",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2. Which 10 brands you chose – provide the frequency table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c6d7e82-d819-495e-8303-e5eeb6a7fa8d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def process_column(column):\n",
    "    data = list(column)\n",
    "    for i in range(len(data)):\n",
    "        text = str(data[i])\n",
    "        for punct in list(string.punctuation.replace('+','')):\n",
    "             text = text.replace(punct, ' ')\n",
    "        text = text.lower()\n",
    "        data[i] = text\n",
    "    return data\n",
    "\n",
    "def replace_car_brands(data, map):\n",
    "    for i in range(len(data)):\n",
    "        text = data[i]\n",
    "        l_text = text.split()\n",
    "        for word in l_text:\n",
    "            if word in map.keys():\n",
    "                text = text.replace(word, map[word])\n",
    "        data[i] = text\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c0b37795-1b5e-401e-bafd-6f4b14896b58",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "comments = process_column(edmunds_data['Comment'])\n",
    "\n",
    "df = spark.read.format('csv').options(header=True,inferSchema=True).load(path + 'Support Files/Substitutions/')\n",
    "brand_model_map = df.toPandas()\n",
    "\n",
    "model__brand_dict = {}\n",
    "for brand, model in zip(brand_model_map['Brand'], brand_model_map['Model']):\n",
    "    model__brand_dict[model] = brand\n",
    "\n",
    "# print(model__brand_dict['century'])\n",
    "comments = replace_car_brands(comments, model__brand_dict)\n",
    "\n",
    "brand_count = {}\n",
    "for brand in list(brand_model_map['Brand'].unique()):\n",
    "    brand_count[brand] = 0\n",
    "\n",
    "for i in range(len(comments)):\n",
    "    text = comments[i].split()\n",
    "    for brand in list(brand_count.keys()):\n",
    "        if brand in text:\n",
    "            brand_count[brand] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "859409f0-f992-4487-be39-6945cc907cc8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "brand_freq = []\n",
    "for brand, count in zip(brand_count.keys(), brand_count.values()):\n",
    "    brand_freq.append([brand, count])\n",
    "\n",
    "brand_freq = pd.DataFrame(brand_freq, columns=['Brand', 'Count'])\n",
    "brand_freq = brand_freq.sort_values('Count', ascending=False).reset_index(drop=False)\n",
    "brand_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc0c43cb-5281-46a6-9aaf-4edc557d347e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3. Show all lift values in a table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "59d12a72-abdb-4797-aecf-fcfe294c23ec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def lift(texts, x, y, words=float('inf')):\n",
    "    n = len(texts)\n",
    "    count_x = 0\n",
    "    count_y = 0\n",
    "    count_x_y = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        x_indices = []\n",
    "        y_indices = []\n",
    "        text = texts[i].split()\n",
    "        \n",
    "        for j in range(len(text)):\n",
    "            if x == text[j]:\n",
    "                x_indices.append(j)\n",
    "            elif y == text[j]:\n",
    "                y_indices.append(j)\n",
    "\n",
    "        n_words = []    \n",
    "        for x_index in x_indices:\n",
    "            for y_index in y_indices:\n",
    "                n_words.append(abs(x_index - y_index) - 1)\n",
    "        \n",
    "        # print(len(n_words) > 0, len(x_indices) > 0, len(y_indices) > 0)\n",
    "        if len(n_words) > 0:\n",
    "            if float(min(n_words)) <= float(words):\n",
    "                count_x_y += 1\n",
    "        if len(x_indices) > 0:\n",
    "            count_x += 1\n",
    "        if len(y_indices) > 0:\n",
    "            count_y += 1\n",
    "        \n",
    "        # print(n, count_x_y, count_x, count_y)\n",
    "    \n",
    "    lift = (n * count_x_y) / (count_x * count_y)\n",
    "    return lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40932ebf-b2eb-421c-bdda-cdcd568ea4e5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "top_10_brands = list(brand_freq[:10]['Brand'])\n",
    "\n",
    "lift_scores = []\n",
    "dissimilarity_matrix = []\n",
    "for i in range(len(top_10_brands)):\n",
    "    row = []\n",
    "    row_diss = []\n",
    "    for j in range(len(top_10_brands)):\n",
    "        if j!=i:\n",
    "            lift_score = lift(comments, top_10_brands[i], top_10_brands[j])\n",
    "            row.append(lift_score)\n",
    "            try:\n",
    "                row_diss.append(1/lift_score)\n",
    "            except ZeroDivisionError:\n",
    "                row_diss.append(np.inf)\n",
    "        elif i==j:\n",
    "            row.append(1)\n",
    "            row_diss.append(0)\n",
    "        # else:\n",
    "        #     row.append(np.nan)\n",
    "        #     row_diss.append(np.nan)\n",
    "    \n",
    "    row.append(top_10_brands[i])\n",
    "    row_diss.append(top_10_brands[i])\n",
    "    lift_scores.append(row)\n",
    "    dissimilarity_matrix.append(row_diss)\n",
    "\n",
    "cols = top_10_brands.append('Brand')\n",
    "\n",
    "lift_scores = pd.DataFrame(lift_scores, columns=top_10_brands).set_index('Brand')\n",
    "display(lift_scores)\n",
    "\n",
    "dissimilarity_matrix = pd.DataFrame(dissimilarity_matrix, columns=top_10_brands).set_index('Brand')\n",
    "display(dissimilarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "89961d74-3d0b-4558-b105-3ec155dd77ab",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 4. MDS Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b72f7057-bae2-4445-88dc-eb53e2b8b761",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def MDS_map(dissimilarity_matrix, metric=True, title='MDS Plot'):\n",
    "    mds = MDS(n_components=2, metric=metric, dissimilarity='precomputed', random_state=0)\n",
    "    pts = mds.fit_transform(dissimilarity_matrix)\n",
    "\n",
    "    plt.scatter(pts[:,0], pts[:,1], color='silver', s=150)\n",
    "    for i in range(dissimilarity_matrix.shape[0]):\n",
    "        plt.annotate(dissimilarity_matrix.index[i], (pts[i,0], pts[i,1]), color='blue')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "MDS_map(dissimilarity_matrix=dissimilarity_matrix, metric=True, title='MDS Plot - Car Brands')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5518c3db-31ab-44b4-a3d8-6d346b843123",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 5. State the 5 attributes you chose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "296be7e0-4d4b-4542-abba-9fde352a3499",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "![Screenshot 2023-09-12 at 6.09.07 PM.png](<attachment:Screenshot 2023-09-12 at 6.09.07 PM.png>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d2642d2-1aaf-4f62-af98-a1d81a5e93a2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The image above illustrates the top words we were able to identify for attributes. The remaining words consisted mainly of punctuation marks or were otherwise not relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6a8a747-2718-4166-9207-7ac0e4c6d5d5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# features = input(\"Enter the features as comma seperated values without spaces\")\n",
    "# features = features.split(',')\n",
    "brand_feature = list(brand_freq[:10]['Brand'])\n",
    "features = ['performance', 'luxury', 'driving', 'engine', 'handling', 'interior']\n",
    "for feature in features:\n",
    "    brand_feature.append(feature)\n",
    "\n",
    "\n",
    "lift_scores = []\n",
    "dissimilarity_matrix = []\n",
    "for i in range(len(brand_feature)):\n",
    "    row = []\n",
    "    row_diss = []\n",
    "    for j in range(len(brand_feature)):\n",
    "        if j!=i:\n",
    "            if (brand_feature[i] in top_10_brands) and (brand_feature[j] in top_10_brands):\n",
    "                lift_score = lift(comments, brand_feature[i], brand_feature[j])\n",
    "            else:\n",
    "                lift_score = lift(comments, brand_feature[i], brand_feature[j], 40)\n",
    "            row.append(lift_score)\n",
    "            try:\n",
    "                row_diss.append(1/lift_score)\n",
    "            except ZeroDivisionError:\n",
    "                row_diss.append(np.inf)\n",
    "        elif i==j:\n",
    "            row.append(1)\n",
    "            row_diss.append(0)\n",
    "        # else:\n",
    "        #     row.append(np.nan)\n",
    "        #     row_diss.append(np.nan)\n",
    "    \n",
    "    row.append(brand_feature[i])\n",
    "    row_diss.append(brand_feature[i])\n",
    "    lift_scores.append(row)\n",
    "    dissimilarity_matrix.append(row_diss)\n",
    "\n",
    "cols = brand_feature.append('Brand')\n",
    "\n",
    "lift_scores = pd.DataFrame(lift_scores, columns=brand_feature).set_index('Brand')\n",
    "display(lift_scores)\n",
    "\n",
    "dissimilarity_matrix = pd.DataFrame(dissimilarity_matrix, columns=brand_feature).set_index('Brand')\n",
    "display(dissimilarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ddb1479-0ac3-409e-afaa-155f0ec88953",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 6. For task F, provide all details of your analysis – e.g., how you measured “aspirational” and how you found the most aspirational brand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5febd8e-a294-4cd5-9988-17cb59dfa799",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "![Screenshot 2023-09-12 at 5.27.41 PM.png](<attachment:Screenshot 2023-09-12 at 5.27.41 PM.png>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f2910420-ce48-4e91-9b66-01f9fb8b3607",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "As you can see in the image above, we are evaluating the Lyft value for each brand against their respective features. Whenever Lyft is greater than 1 for a particular feature, we assign it a score of 1; otherwise, we assign a score of 0. \n",
    "Based on this analysis, Audi seems to be the most aspirational brand, while for luxury, Lexus and Cadillac stand out as excellent choices!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02816a1d-0c19-4918-b766-9e3a1b573b53",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 7. Advice/insights based on your analysis for your client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "61e5c7e3-a260-4712-af7e-0fbc4b457383",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Advice/insights based on your analysis for your client\n",
    "Based on the analysis of brand preferences within luxury segments and the relationships between different automotive brands, here are some advice and insights for your client:\n",
    "\n",
    "*1. Brand Synergy and Cross-Promotion:*\n",
    "   - Clients who prefer luxury brands like Lexus, Mercedes, and Cadillac tend to have similar preferences. Encourage cross-promotion or partnerships between these brands to capture a broader customer base.\n",
    "   - Consider joint marketing efforts or collaborations to leverage the shared appeal among these luxury brands.\n",
    "\n",
    "*2. Leveraging the German Luxury Cluster:*\n",
    "   - Given the high similarity values between BMW, Audi, and Mercedes, target marketing strategies towards consumers who appreciate German luxury engineering and design.\n",
    "   - Highlight the strengths and unique features of each brand within this cluster to differentiate them while appealing to the shared preferences.\n",
    "\n",
    "*3. Exploring Japanese Brand Synergy:*\n",
    "   - Recognize that Toyota and Honda share a moderate level of similarity, suggesting some customer overlap. Develop marketing initiatives or offers that cater to consumers who prefer both Japanese brands.\n",
    "   - For Acura, focus on its unique value proposition and characteristics to target a slightly different customer base within the Japanese automaker market.\n",
    "\n",
    "*4. Understanding Infiniti's Niche:*\n",
    "   - Infiniti's relative isolation indicates a unique market position or a different target audience. Conduct market research to identify the specific consumer segment that Infiniti appeals to and tailor marketing efforts accordingly.\n",
    "   - Highlight the distinctive qualities of Infiniti vehicles to attract and retain this niche customer base.\n",
    "\n",
    "*5. Volkswagen's Versatility:*\n",
    "   - Volkswagen's moderate similarity with various brands suggests that it occupies a middle ground between different car segments. Leverage this versatility to appeal to a broader range of consumers.\n",
    "   - Emphasize Volkswagen's adaptability, offering vehicles that can meet a variety of customer needs and preferences.\n",
    "\n",
    "*6. Cadillac's Competitive Landscape:*\n",
    "   - Cadillac's lower similarity with other American brands and higher correlations with European luxury brands suggest that it competes more directly with European luxury brands.\n",
    "   - Position Cadillac as a strong contender in the European luxury segment and emphasize the qualities that make it competitive within this category.\n",
    "\n",
    "*7. Capitalize on the Lexus-Toyota Connection:*\n",
    "   - The strong similarity between Lexus and Toyota indicates a strong connection between the two brands. Leverage Toyota's reputation for reliability to attract consumers to the Lexus luxury offerings.\n",
    "   - Highlight the shared commitment to quality and reliability in marketing campaigns for both brands.\n",
    "\n",
    "In conclusion, understanding the relationships and preferences among luxury automotive brands can guide your client's marketing and strategic decisions. Tailoring marketing efforts to capitalize on brand synergy, targeting specific customer segments, and emphasizing unique brand qualities are key strategies to maximize success in the competitive luxury automobile market."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Final Notebook_V2.0",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

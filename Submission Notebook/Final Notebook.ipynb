{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5253f05d-8277-4ba2-b55a-6df88cab3bf6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Team Members Name (eid):\n",
    "1. Ko Choi (kec788)\n",
    "2. Mandeep Burdak (msb4384)\n",
    "3. Nishant Kushwaha (nsk779)\n",
    "4. Pratyush Sharma (ps35484)\n",
    "5. Vaibhav Nagar (vn5339)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f183aefc-a1c3-41c7-aa5b-b2e4736e73c6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 1. Scraper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f53dfea-4a93-4bf4-97f5-f748dad8e368",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import statsmodels.api as sm\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "from sklearn.manifold import MDS\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6dc063a-d107-48ff-a6d0-deedc52a4a95",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "path = '/mnt/car_brand_attribute_associations/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "314a7283-93ce-4298-83c7-1a511caadd86",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "wd = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "n = 6000\n",
    "data = {}\n",
    "user_dict = {}\n",
    "posts_dict = {}\n",
    "time_dict = {}\n",
    "i = 435\n",
    "while len(data) < n:\n",
    "    url = 'https://forums.edmunds.com/discussion/2864/general/x/entry-level-luxury-performance-sedans' + \"/p\" + str(i)\n",
    "    wd.get(url)\n",
    "\n",
    "    comments = wd.find_elements(By.CLASS_NAME, value=\"Comment\")\n",
    "\n",
    "    for comment in reversed(comments): \n",
    "        user = comment.find_element(By.TAG_NAME, \"a\").get_attribute('href')\n",
    "        user = user.split('/')[-1]\n",
    "        \n",
    "        posts = comment.find_element(by=By.CLASS_NAME, value=\"AuthorInfo\")\n",
    "        posts = posts.find_element(by=By.TAG_NAME, value=\"b\").text\n",
    "        posts = posts.split(',')\n",
    "        posts = \"\".join(posts)\n",
    "        \n",
    "        time = comment.find_element(by=By.TAG_NAME, value=\"time\").get_attribute(\"datetime\")\n",
    "\n",
    "        try:\n",
    "            backquote = comment.find_element(by=By.CLASS_NAME, value=\"Item-BodyWrap\")\n",
    "            backquote = backquote.find_element(by=By.TAG_NAME, value=\"blockquote\")\n",
    "            backquote = backquote.find_element(by=By.CLASS_NAME, value=\"QuoteText.blockquote-content\").text\n",
    "            backquote = backquote.split()\n",
    "            backquote = \" \".join(backquote)\n",
    "            backquote = backquote.strip()\n",
    "        except:\n",
    "            backquote = \"\"\n",
    "        \n",
    "        comment_text = comment.find_element(by=By.CLASS_NAME, value=\"Item-BodyWrap\")\n",
    "        comment_text = comment.find_element(by=By.CLASS_NAME, value=\"Message.userContent\").text\n",
    "        comment_text = comment_text.split()\n",
    "        comment_text = \" \".join(comment_text)\n",
    "        comment_text = comment_text.strip()\n",
    "\n",
    "        try:\n",
    "            sub_text = comment.find_element(by=By.CLASS_NAME, value=\"Item-BodyWrap\")\n",
    "            sub_text = sub_text.find_element(by=By.TAG_NAME, value=\"blockquote\").text\n",
    "            sub_text = sub_text.split()\n",
    "            sub_text = \" \".join(sub_text)\n",
    "            sub_text = sub_text.strip()\n",
    "        except:\n",
    "            sub_text = ''\n",
    "\n",
    "        comment_text = comment_text.replace(sub_text, \"\").strip()\n",
    "\n",
    "        user_dict[comment_text] = user\n",
    "        posts_dict[comment_text] = posts\n",
    "        time_dict[comment_text] = time\n",
    "\n",
    "        if backquote != \"\":\n",
    "            if comment_text in data.keys():\n",
    "                text = [comment_text]\n",
    "                for j in data[comment_text]:\n",
    "                    text.append(j)\n",
    "                data[backquote] = text\n",
    "                del data[comment_text]\n",
    "            else:\n",
    "                data[backquote] = [comment_text]\n",
    "        else:\n",
    "            if comment_text not in data.keys():\n",
    "                data[comment_text] = []\n",
    "\n",
    "    l = 30\n",
    "    d = int((len(data)/n) * l)\n",
    "    sys.stdout.write(\"\\rCollecing samples from {1}: {0}>\".format(\"=\"*d + \".\"*(l-d-1), url))\n",
    "    sys.stdout.flush()\n",
    "    i = int(i)\n",
    "    i = i - 1\n",
    "wd.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd57245e-531f-4767-8569-6a77f253891d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "edmunds = []\n",
    "for key in data.keys():\n",
    "    text = ' '\n",
    "    text += key\n",
    "    for j in data[key]:\n",
    "        text += ' ' + j\n",
    "    text.strip()\n",
    "\n",
    "    try:\n",
    "        user = user_dict[key]\n",
    "    except KeyError:\n",
    "        user = None\n",
    "    \n",
    "    try: \n",
    "        n_posts = posts_dict[key]\n",
    "    except KeyError:\n",
    "        n_posts = None\n",
    "\n",
    "    try:\n",
    "        time = time_dict[key]\n",
    "    except KeyError:\n",
    "        time = None\n",
    "    \n",
    "    edmunds.append([user, time, text, n_posts])\n",
    "\n",
    "edmunds = pd.DataFrame(edmunds, columns=['User', 'Post Time', 'Comment', '#Posts by User'])\n",
    "edmunds['Post Time'] = pd.to_datetime(edmunds['Post Time'])\n",
    "edmunds = edmunds.loc[~edmunds['Comment'].isnull()]\n",
    "edmunds = edmunds.loc[~edmunds['Post Time'].isnull()]\n",
    "edmunds = edmunds[:5000]\n",
    "df_spark = spark.createDataFrame(edmunds)\n",
    "df_spark.write.option(\"header\", \"true\").mode(\"overwrite\").csv(path+'Data/Edmunds_Data_New')\n",
    "edmunds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de8d055d-2c22-4689-b43a-143724ca340a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### OLS- Zipf's Law verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9630b816-b023-4679-9c7b-e23bf2a00a97",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "edmunds_data = edmunds\n",
    "edmunds_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b95a8a5-bdd6-407b-b913-38f7d638b7f6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generate_corpus(column):\n",
    "    corpus = \" \"\n",
    "    for text in column:\n",
    "        text = str(text)\n",
    "        for i in list(string.punctuation.replace('+','')):\n",
    "            text = text.replace(i, ' ')\n",
    "        text = text.lower()\n",
    "\n",
    "        corpus += text\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f984057-2ae9-41bb-ae6d-3ab8eb2933bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "corpus = generate_corpus(edmunds_data['Comment'])\n",
    "corpus = corpus.split()\n",
    "print(len(corpus))\n",
    "\n",
    "word_freq = FreqDist()\n",
    "for word in tqdm(corpus):\n",
    "    word_freq[word] += 1\n",
    "\n",
    "freq_dist = []\n",
    "for rank, word in enumerate(word_freq):\n",
    "    freq_dist.append([rank+1, word, word_freq[word]])\n",
    "\n",
    "freq_dist = pd.DataFrame(freq_dist, columns=['Rank', 'Word', 'Count'])\n",
    "df = spark.createDataFrame(freq_dist)\n",
    "df.write.option(\"header\", \"true\").mode(\"overwrite\").csv(path+ 'Support Files/Freq_Dist_new_comments')\n",
    "freq_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa521f85-3a88-479f-a7ab-6f745a414b00",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "max_rank = max(freq_dist['Rank'])\n",
    "c = max_rank * int(freq_dist.loc[freq_dist['Rank'] == max_rank]['Count'].values)\n",
    "\n",
    "l_rank = np.log(freq_dist['Rank'] / c)\n",
    "l_freq = np.log(freq_dist['Count'])\n",
    "\n",
    "# X = sm.add_constant(l_rank)\n",
    "model = sm.OLS(l_freq, l_rank)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86d63821-215a-434b-ad94-a7d0594bc239",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,7))\n",
    "plt.plot(l_freq, l_rank, label=\"Raw Zipf's Curve\")\n",
    "plt.plot(result.predict(l_rank), l_rank, label='OLS Fit')\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(\"Zipf's Distribution\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5aad36da-60fd-4c37-8b3f-739ddcb42257",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2. Which 10 brands you chose – provide the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24d113ed-f115-4866-bb26-f081807e96e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def process_column(column):\n",
    "    data = list(column)\n",
    "    for i in range(len(data)):\n",
    "        text = str(data[i])\n",
    "        for punct in list(string.punctuation.replace('+','')):\n",
    "             text = text.replace(punct, ' ')\n",
    "        text = text.lower()\n",
    "        data[i] = text\n",
    "    return data\n",
    "\n",
    "def replace_car_brands(data, map):\n",
    "    for i in range(len(data)):\n",
    "        text = data[i]\n",
    "        l_text = text.split()\n",
    "        for word in l_text:\n",
    "            if word in map.keys():\n",
    "                text = text.replace(word, map[word])\n",
    "        data[i] = text\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4254f02b-91d9-4220-abbf-024cb484a4d0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "comments = process_column(edmunds_data['Comment'])\n",
    "\n",
    "df = spark.read.format('csv').options(header=True,inferSchema=True).load(path + 'Support Files/Substitutions/')\n",
    "brand_model_map = df.toPandas()\n",
    "\n",
    "model__brand_dict = {}\n",
    "for brand, model in zip(brand_model_map['Brand'], brand_model_map['Model']):\n",
    "    model__brand_dict[model] = brand\n",
    "\n",
    "# print(model__brand_dict['century'])\n",
    "comments = replace_car_brands(comments, model__brand_dict)\n",
    "\n",
    "brand_count = {}\n",
    "for brand in list(brand_model_map['Brand'].unique()):\n",
    "    brand_count[brand] = 0\n",
    "\n",
    "for i in range(len(comments)):\n",
    "    text = comments[i].split()\n",
    "    for brand in list(brand_count.keys()):\n",
    "        if brand in text:\n",
    "            brand_count[brand] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f25d94fa-0229-4433-9565-12f5c6a29299",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "brand_freq = []\n",
    "for brand, count in zip(brand_count.keys(), brand_count.values()):\n",
    "    brand_freq.append([brand, count])\n",
    "\n",
    "brand_freq = pd.DataFrame(brand_freq, columns=['Brand', 'Count'])\n",
    "brand_freq = brand_freq.sort_values('Count', ascending=False).reset_index(drop=False)\n",
    "brand_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a858a3b-39c8-4448-aef2-021f8ad1c531",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3. Show all lift values in a table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f80464bc-3020-4adb-ae48-284b084a2232",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def lift(texts, x, y, words=float('inf')):\n",
    "    n = len(texts)\n",
    "    count_x = 0\n",
    "    count_y = 0\n",
    "    count_x_y = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        x_indices = []\n",
    "        y_indices = []\n",
    "        text = texts[i].split()\n",
    "        \n",
    "        for j in range(len(text)):\n",
    "            if x == text[j]:\n",
    "                x_indices.append(j)\n",
    "            elif y == text[j]:\n",
    "                y_indices.append(j)\n",
    "\n",
    "        n_words = []    \n",
    "        for x_index in x_indices:\n",
    "            for y_index in y_indices:\n",
    "                n_words.append(abs(x_index - y_index) - 1)\n",
    "        \n",
    "        # print(len(n_words) > 0, len(x_indices) > 0, len(y_indices) > 0)\n",
    "        if len(n_words) > 0:\n",
    "            if float(min(n_words)) <= float(words):\n",
    "                count_x_y += 1\n",
    "        if len(x_indices) > 0:\n",
    "            count_x += 1\n",
    "        if len(y_indices) > 0:\n",
    "            count_y += 1\n",
    "        \n",
    "        # print(n, count_x_y, count_x, count_y)\n",
    "    \n",
    "    lift = (n * count_x_y) / (count_x * count_y)\n",
    "    return lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd1763bf-5181-495e-b6b3-4dd6bdf76187",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "top_10_brands = list(brand_freq[:10]['Brand'])\n",
    "\n",
    "lift_scores = []\n",
    "dissimilarity_matrix = []\n",
    "for i in range(len(top_10_brands)):\n",
    "    row = []\n",
    "    row_diss = []\n",
    "    for j in range(len(top_10_brands)):\n",
    "        if j!=i:\n",
    "            lift_score = lift(comments, top_10_brands[i], top_10_brands[j])\n",
    "            row.append(lift_score)\n",
    "            try:\n",
    "                row_diss.append(1/lift_score)\n",
    "            except ZeroDivisionError:\n",
    "                row_diss.append(np.inf)\n",
    "        elif i==j:\n",
    "            row.append(1)\n",
    "            row_diss.append(0)\n",
    "        # else:\n",
    "        #     row.append(np.nan)\n",
    "        #     row_diss.append(np.nan)\n",
    "    \n",
    "    row.append(top_10_brands[i])\n",
    "    row_diss.append(top_10_brands[i])\n",
    "    lift_scores.append(row)\n",
    "    dissimilarity_matrix.append(row_diss)\n",
    "\n",
    "cols = top_10_brands.append('Brand')\n",
    "\n",
    "lift_scores = pd.DataFrame(lift_scores, columns=top_10_brands).set_index('Brand')\n",
    "display(lift_scores)\n",
    "\n",
    "dissimilarity_matrix = pd.DataFrame(dissimilarity_matrix, columns=top_10_brands).set_index('Brand')\n",
    "display(dissimilarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82d53284-2d38-4f76-ac6a-0f414b24589c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 4. MDS Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4c6116c-a2f5-4895-b6e6-089d53efc697",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def MDS_map(dissimilarity_matrix, metric=True, title='MDS Plot'):\n",
    "    mds = MDS(n_components=2, metric=metric, dissimilarity='precomputed', random_state=0)\n",
    "    pts = mds.fit_transform(dissimilarity_matrix)\n",
    "\n",
    "    plt.scatter(pts[:,0], pts[:,1], color='silver', s=150)\n",
    "    for i in range(dissimilarity_matrix.shape[0]):\n",
    "        plt.annotate(dissimilarity_matrix.index[i], (pts[i,0], pts[i,1]), color='blue')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "MDS_map(dissimilarity_matrix=dissimilarity_matrix, metric=True, title='MDS Plot - Car Brands')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f8c3a7c-a901-4471-bbbe-c56b2bf21e3e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 5. State the 5 attributes you chose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7312fe37-8538-4df2-abcd-59d9f4f25329",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# features = input(\"Enter the features as comma seperated values without spaces\")\n",
    "# features = features.split(',')\n",
    "brand_feature = list(brand_freq[:10]['Brand'])\n",
    "features = ['performance', 'luxury', 'driving', 'engine', 'handling', 'interior']\n",
    "for feature in features:\n",
    "    brand_feature.append(feature)\n",
    "\n",
    "\n",
    "lift_scores = []\n",
    "dissimilarity_matrix = []\n",
    "for i in range(len(brand_feature)):\n",
    "    row = []\n",
    "    row_diss = []\n",
    "    for j in range(len(brand_feature)):\n",
    "        if j!=i:\n",
    "            if (brand_feature[i] in top_10_brands) and (brand_feature[j] in top_10_brands):\n",
    "                lift_score = lift(comments, brand_feature[i], brand_feature[j])\n",
    "            else:\n",
    "                lift_score = lift(comments, brand_feature[i], brand_feature[j], 40)\n",
    "            row.append(lift_score)\n",
    "            try:\n",
    "                row_diss.append(1/lift_score)\n",
    "            except ZeroDivisionError:\n",
    "                row_diss.append(np.inf)\n",
    "        elif i==j:\n",
    "            row.append(1)\n",
    "            row_diss.append(0)\n",
    "        # else:\n",
    "        #     row.append(np.nan)\n",
    "        #     row_diss.append(np.nan)\n",
    "    \n",
    "    row.append(brand_feature[i])\n",
    "    row_diss.append(brand_feature[i])\n",
    "    lift_scores.append(row)\n",
    "    dissimilarity_matrix.append(row_diss)\n",
    "\n",
    "cols = brand_feature.append('Brand')\n",
    "\n",
    "lift_scores = pd.DataFrame(lift_scores, columns=brand_feature).set_index('Brand')\n",
    "display(lift_scores)\n",
    "\n",
    "dissimilarity_matrix = pd.DataFrame(dissimilarity_matrix, columns=brand_feature).set_index('Brand')\n",
    "display(dissimilarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3958d4d2-f687-4f45-b119-43c2abfa1fd9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Here are some insights that can be derived from the similarity or correlation matrix:\n",
    "\n",
    "    Brand Preferences within Luxury Segments: The matrix suggests that within the luxury car segment, brands like Lexus, Mercedes, and Cadillac tend to be more closely correlated with each other. This could indicate that consumers who prefer one of these luxury brands are more likely to consider the others as well.\n",
    "\n",
    "    German Luxury Brands: Brands like BMW, Audi, and Mercedes have relatively high similarity values with each other. This suggests that consumers who like one German luxury brand are likely to have a preference for others in the same category.\n",
    "\n",
    "    Japanese Brands: Toyota and Honda show a moderate level of similarity, indicating that consumers who prefer one Japanese brand may also consider the other. Acura, which is also a Japanese brand, has a somewhat lower similarity with both Toyota and Honda, suggesting it may target a slightly different customer base within the Japanese automaker market.\n",
    "\n",
    "    Infiniti's Isolation: Infiniti stands out as being relatively less correlated with the other brands. This could indicate that it has a unique market position or appeals to a different type of consumer compared to the other brands in the table.\n",
    "\n",
    "    Volkswagen's Position: Volkswagen has moderate similarity values with various brands, indicating it may occupy a middle ground between different car segments, appealing to a broader range of consumers.\n",
    "\n",
    "    American Luxury: Cadillac, although being an American luxury brand, has relatively low similarity values with other American brands like Ford or Chevrolet, but it shows higher correlations with European luxury brands like Mercedes and German luxury brands like Audi and BMW. This suggests that Cadillac may compete more directly with European luxury brands than with other American brands.\n",
    "\n",
    "    Strong Similarity between Lexus and Toyota: Lexus, the luxury division of Toyota, has a very high similarity with its parent brand, indicating a strong connection between the two. This suggests that consumers who trust Toyota's reputation for reliability may also be drawn to Lexus for its luxury offerings.\n",
    "\n",
    "These insights can be valuable for market analysis, brand positioning, and marketing strategies within the automotive industry. They provide an understanding of how different car brands are perceived by consumers and their potential market overlaps or distinctions."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Final Notebook",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
